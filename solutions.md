## Q. How to ensure that items are sampled in IID fashion.

## Q. What happens when mentioned constraints cannot be met

## Q. When the datalake is large, how will my sampler perform

## Q. Choices made to make code maintainable and scalable

## Q. What sort of tests make sense to include? What edge cases user might face, does my code handle those ?  

## Q. Suppose the datalake had millions of records instead of thousands what programming language, database and cloud storage will be optimal. Would you change how the metadata is stored ? How would you modify your sampler to work with the new datalake ?
